{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char Prediction using LSTM\n",
    "\n",
    "1. Download data of Alice in Wonderland or Dracula from https://www.gutenberg.org/browse/scores/top in plain text format\n",
    "2. Create an char_to_int map which maps each character used in the novel to an integer. example {a: 3}\n",
    "3. Read data from the text file and do the following: 3.1 Create a sliding window in which it takes in first 100 characters as   the input sequence and 101th character as the output sequence. (It slides over every character). For example:\n",
    "         \"Avul Pakir Jainulabdeen Abdul Kalam better known as A.P.J. Abdul Kalam\"\n",
    "         You should slide from \"A\" to the 100th char and 101th char will be your output.\n",
    "         Then you should start sliding from \"v\" to the 100th char and 101th char will be your output.\n",
    "   The input and the output sequence should be converted to their integer representation using the char_to_int map. With this you basically have two arrays seqIn and seqOut with each element containing integer representation of 100 characters and 1 character respectively. seqIn = [[10........15], [5.....25]...] seqOut = [5, 2, 5]\n",
    "4. Now reshape your seqIn as (NumberOfSamples, 100, 1) - So you basically get this [[[10]........[15]], [[5]..... [25]]...]\n",
    "5. One hot encode your seqOut using np_utils.to_categorical\n",
    "6. Now create a simple model with LSTM followed by a Dense layer.\n",
    "7. Then, given a seed sentence predict the next character using the model created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import keras\n",
    "# Sequence to attain Padding\n",
    "from keras.preprocessing import sequence\n",
    "# Importing RNN's LSTM\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "# Applying Sequential algorithm to model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('AliceinWonderland.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all '\\n' from the document\n",
    "file = file.replace('\\n',' ').replace('\\r','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation the number of unique letter in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "# Stores the unique letters from the document\n",
    "chars = list(set(file))\n",
    "\n",
    "# Stores the number of unique letters which is the num_classes in outputs\n",
    "unique_chars_count = len(chars)\n",
    "print(unique_chars_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert text letters to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Networks accepts only number inputs, so converting text(letters) into numbers\n",
    "\n",
    "## Maps letters to numbers\n",
    "char_to_int = dict(zip(chars, [i for i in range(len(chars))]))\n",
    "\n",
    "## Maps numbers back to text\n",
    "int_to_char = dict(zip([i for i in range(len(chars))], chars ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' SLIDING FUNCTION: Slides over the input text file character by character'''\n",
    "\n",
    "def slider(data, slide):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data)-slide):\n",
    "        x.append([char for char in data[i:i+slide]])\n",
    "        y.append(data[i+slide])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' CHAR TO INT CONVERSION FUNCTION: Converts character dataset to int dataset '''\n",
    "\n",
    "def char_data_to_int_data(x,y, char_to_int):\n",
    "    input_int = []\n",
    "    output_int = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        input_int.append([char_to_int[char] for char in x[i]])\n",
    "        output_int.append([char_to_int[char] for char in y[i]])\n",
    "    return input_int,output_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' INTIALIZATION FUNCTION: Accepts tokenized words, slide, list of unique words from the doc '''\n",
    "\n",
    "def main(data, slide, char_to_int):\n",
    "    x, y = slider(data, slide)\n",
    "    input_int, output_int = char_data_to_int_data(x, y, char_to_int)\n",
    "    output_int = list(np.array(output_int).flatten())\n",
    "    input_int = np.array(input_int).reshape(len(input_int),slide,1)\n",
    "    return input_int,output_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = main(file,100,char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163715, 100, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' X=(163716, 100, 1) \n",
    "\n",
    "    Number of samples = 163716\n",
    "    Number of inputs  = 100 (Letter1, Letter2...., Letter100)\n",
    "               Output = 1 (Letter101th)\n",
    "'''\n",
    "\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163715"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.01, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding Output Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total no. of classes = Unique Values in the document, [0,0,0,.....1]\n",
    "y_train_oneHotEncoded = keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_oneHotEncoded = keras.utils.to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162077, 100, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162077, 85)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oneHotEncoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 162077 samples, validate on 1638 samples\n",
      "Epoch 1/1\n",
      "162077/162077 [==============================] - 631s 4ms/step - loss: 2.9123 - acc: 0.2279 - val_loss: 2.6964 - val_acc: 0.2985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x192d46c6b38>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(unique_chars_count, activation=\"sigmoid\"))\n",
    "## Compiling Model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "## Fitting Model without weights(Wr or Wht-1)\n",
    "model.fit(x_train, y_train_oneHotEncoded, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test_oneHotEncoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loading Weights\n",
    "#model.load_weights('weights-improvement-49-1.2575.hdf5', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loading Weights\n",
    "#model.add(Dropout(32, input_shape=(x_train.shape[1], x_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638/1638 [==============================] - 2s 967us/step\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(x_test, y_test_oneHotEncoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.853479853479854"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = evaluate[1]\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = \"Project Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org Title: Alice’s Adventures in Wonderland Author: Lew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x, test_y = main(test,100,char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 100, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = model.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "actual = []\n",
    "for i,j in zip(pre,test_y):\n",
    "    output.append(int_to_char[i])\n",
    "    actual.append(int_to_char[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  n\n",
      "predicted :     Actual :  y\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  n\n",
      "predicted :     Actual :  y\n",
      "predicted :     Actual :  w\n",
      "predicted :     Actual :  h\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  n\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  c\n",
      "predicted :  a  Actual :  o\n",
      "predicted :  i  Actual :  s\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  n\n",
      "predicted :     Actual :  d\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  w\n",
      "predicted :  a  Actual :  i\n",
      "predicted :  t  Actual :  t\n",
      "predicted :     Actual :  h\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  l\n",
      "predicted :     Actual :  m\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  n\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  r\n",
      "predicted :  o  Actual :  e\n",
      "predicted :  r  Actual :  s\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  i\n",
      "predicted :     Actual :  c\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :  i\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  w\n",
      "predicted :  a  Actual :  h\n",
      "predicted :  i  Actual :  a\n",
      "predicted :  t  Actual :  t\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  v\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  .\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :   \n",
      "predicted :     Actual :  Y\n",
      "predicted :  o  Actual :  o\n",
      "predicted :     Actual :  u\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  m\n",
      "predicted :     Actual :  a\n",
      "predicted :     Actual :  y\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  c\n",
      "predicted :  a  Actual :  o\n",
      "predicted :  i  Actual :  p\n",
      "predicted :     Actual :  y\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  i\n",
      "predicted :  o  Actual :  t\n",
      "predicted :     Actual :  ,\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  g\n",
      "predicted :  h  Actual :  i\n",
      "predicted :  r  Actual :  v\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  i\n",
      "predicted :  o  Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  w\n",
      "predicted :     Actual :  a\n",
      "predicted :     Actual :  y\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  o\n",
      "predicted :  h  Actual :  r\n",
      "predicted :  r  Actual :   \n",
      "predicted :  t  Actual :  r\n",
      "predicted :  o  Actual :  e\n",
      "predicted :  r  Actual :  -\n",
      "predicted :     Actual :  u\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  i\n",
      "predicted :  o  Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  u\n",
      "predicted :  o  Actual :  n\n",
      "predicted :     Actual :  d\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  t\n",
      "predicted :  h  Actual :  h\n",
      "predicted :  e  Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  t\n",
      "predicted :  h  Actual :  e\n",
      "predicted :  r  Actual :  r\n",
      "predicted :     Actual :  m\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  o\n",
      "predicted :  h  Actual :  f\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  t\n",
      "predicted :  h  Actual :  h\n",
      "predicted :  e  Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  P\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  j\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  c\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  G\n",
      "predicted :     Actual :  u\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  b\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  g\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  L\n",
      "predicted :     Actual :  i\n",
      "predicted :     Actual :  c\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  i\n",
      "predicted :  o  Actual :  n\n",
      "predicted :     Actual :  c\n",
      "predicted :     Actual :  l\n",
      "predicted :     Actual :  u\n",
      "predicted :     Actual :  d\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  d\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  w\n",
      "predicted :  a  Actual :  i\n",
      "predicted :  t  Actual :  t\n",
      "predicted :     Actual :  h\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  t\n",
      "predicted :  h  Actual :  h\n",
      "predicted :  e  Actual :  i\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  e\n",
      "predicted :  a  Actual :  B\n",
      "predicted :  e  Actual :  o\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  k\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  o\n",
      "predicted :  h  Actual :  r\n",
      "predicted :  r  Actual :   \n",
      "predicted :  t  Actual :  o\n",
      "predicted :  h  Actual :  n\n",
      "predicted :     Actual :  l\n",
      "predicted :     Actual :  i\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  a\n",
      "predicted :  n  Actual :  t\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  w\n",
      "predicted :  a  Actual :  w\n",
      "predicted :  r  Actual :  w\n",
      "predicted :  r  Actual :  .\n",
      "predicted :     Actual :  g\n",
      "predicted :     Actual :  u\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  b\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  g\n",
      "predicted :     Actual :  .\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  g\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  T\n",
      "predicted :  a  Actual :  i\n",
      "predicted :  t  Actual :  t\n",
      "predicted :     Actual :  l\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  :\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  A\n",
      "predicted :  a  Actual :  l\n",
      "predicted :  i  Actual :  i\n",
      "predicted :     Actual :  c\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  ’\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  A\n",
      "predicted :  a  Actual :  d\n",
      "predicted :  r  Actual :  v\n",
      "predicted :  r  Actual :  e\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  t\n",
      "predicted :     Actual :  u\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  s\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  i\n",
      "predicted :  o  Actual :  n\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  W\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  d\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  l\n",
      "predicted :     Actual :  a\n",
      "predicted :     Actual :  n\n",
      "predicted :     Actual :  d\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  A\n",
      "predicted :  a  Actual :  u\n",
      "predicted :  t  Actual :  t\n",
      "predicted :     Actual :  h\n",
      "predicted :     Actual :  o\n",
      "predicted :     Actual :  r\n",
      "predicted :     Actual :  :\n",
      "predicted :     Actual :   \n",
      "predicted :  t  Actual :  L\n",
      "predicted :     Actual :  e\n",
      "predicted :     Actual :  w\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(output,actual):\n",
    "    print(\"predicted : \",i,\" Actual : \",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
